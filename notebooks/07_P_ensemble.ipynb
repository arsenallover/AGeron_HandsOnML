{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598628432922",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting Classifier : Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4)\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "svc_clf = SVC()\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[(\"lr\", log_clf), (\"svm\", svc_clf), (\"rf\", rf_clf)], voting = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LogisticRegression 0.848\nRandomForestClassifier 0.8505\nSVC 0.868\nVotingClassifier 0.8645\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)#, random_state = 42)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rf_clf, svc_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8665"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500, bootstrap = True, max_samples = 100, n_jobs = -1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.85975"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "### OOB Evaluation\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500, bootstrap = True, max_samples = 100, n_jobs = -1, oob_score = True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sepal length (cm) 0.09891613568588883\nsepal width (cm) 0.024937877435850644\npetal length (cm) 0.4257493352666834\npetal width (cm) 0.4503966516115772\n"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs = -1)\n",
    "rnd_clf.fit(iris['data'], iris['target'])\n",
    "\n",
    "for names, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(names, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n                   learning_rate=0.5, n_estimators=200)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1),\n",
    "n_estimators = 200, algorithm = 'SAMME.R', learning_rate = 0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.863"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston['data'], boston[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "25.993190895971193\n"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Basic Tree\n",
    "tree_reg = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "y_pred = tree_reg.predict(X_test)\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.ensemble import RandomForestClassifier\\nimport sklearn\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21.605190702000193\n"
    }
   ],
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "# Tree 1\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg1.fit(X_train, y_train)\n",
    "y_pred1 = tree_reg1.predict(X_train)\n",
    "\n",
    "# Tree 2\n",
    "y_error1 = y_train - y_pred1\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg2.fit(X_train, y_error1)\n",
    "y_pred2 = tree_reg2.predict(X_train)\n",
    "\n",
    "# Tree 3\n",
    "y_error2 = y_error1 - y_pred2\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg3.fit(X_train, y_error2)\n",
    "y_pred3 = tree_reg3.predict(X_train)\n",
    "\n",
    "final_prediction = np.sum(tree.predict(X_test) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "\n",
    "print(mean_squared_error(final_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21.605190702000183"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "## Gradient Boosting : Scikit\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 3, learning_rate = 1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "y_pred = gbrt.predict(X_test)\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "51.08895704979148\n"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 3, learning_rate = 0.1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "y_pred = gbrt.predict(X_test)\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "14.61533125232632\n"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 300, learning_rate = 1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "y_pred = gbrt.predict(X_test)\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9.8373719804626\n"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 300, learning_rate = 0.1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "y_pred = gbrt.predict(X_test)\n",
    "print(mean_squared_error(y_pred, y_test))"
   ]
  }
 ]
}